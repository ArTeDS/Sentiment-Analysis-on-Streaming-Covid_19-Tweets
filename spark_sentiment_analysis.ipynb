{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArTeDS/Sentiment-Analysis-on-Streaming-Covid_19-Tweets/blob/main/spark_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4TOSsHbUms_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "INSTRUCTIONS:\n",
        "1) Download Spark manually and extract it to whichever directory you want\n",
        "2) Download Java jdk 8 (might work with 11). It doesn't work with later versions\n",
        "3) For Hadoop to work, download winutils. Choose the right version according to the Hadoop version you downloaded\n",
        "\n",
        "link: https://github.com/steveloughran/winutils\n",
        "\n",
        "From Hadoop version 3.1 and later versions, the winutils is downloaded by the GitHub of another user. \n",
        "A link is provided on the link above. \n",
        "\n",
        "Both the wintutils.exe and hadoop.dll must be downloaded and placed in a folder named hadoop\\bin\n",
        "\n",
        "After putting hadoop.dll and winutils in hadoop/bin folder, you also need to put \n",
        "hadoop.dll into the C:\\Windows\\System32 folder\n",
        "\n",
        "4) Create environment variables providing the paths for spark, java jdk, and hadoop, according to the \n",
        "paths you have placed each. Below are my paths. Change them with yours. If working with notebooks, do that on a cell.\n",
        "If using PyCharm, set the environment variables on the configuration.\n",
        "\n",
        "5) Before you import pyspark modules, install findspark and run the following code:\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "Example:\n",
        "import os    \n",
        "os.environ['SPARK_HOME'] = 'C:\\spark\\spark-3.2.0-bin-hadoop3.2'\n",
        "os.environ['JAVA_HOME'] = 'C:\\Program Files\\Java\\jdk1.8.0_311'\n",
        "os.environ['HADOOP_HOME'] = 'C:\\hadoop'\n",
        "\n",
        "6) If not installed, install Microsoft Visual C++ 2010. It has to be the 2010 edition\n",
        "\n",
        "7) If working on notebooks, after running the codes, open a cmd and type telnet localhost port (e.g. telnet 127.0.0.1 5555). \n",
        "You may have to activate the telnet client from Windows Features (search on Google how to do that). \n",
        "If using Pycharm, just create and run an HTTP client. You can find that in Tools.\n",
        "\n",
        "'''\n",
        "import os    \n",
        "os.environ['SPARK_HOME'] = 'C:\\spark\\spark-3.2.0-bin-hadoop3.2'\n",
        "os.environ['JAVA_HOME'] = 'C:\\Program Files\\Java\\jdk1.8.0_311'\n",
        "os.environ['HADOOP_HOME'] = 'C:\\hadoop'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veUTf3OvUmtI"
      },
      "outputs": [],
      "source": [
        "# ! pip install textblob\n",
        "# ! pip install findspark\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.streaming import StreamingContext\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import DataFrameWriter\n",
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "def preprocessing(lines):\n",
        "    words = lines.select(explode(split(lines.value, \"t_end\")).alias(\"word\"))\n",
        "    words = words.na.replace('', None)\n",
        "    words = words.na.drop()\n",
        "    words = words.withColumn('word', F.regexp_replace('word', r'http\\S+', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', '@\\w+', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', '#', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', 'RT', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', ':', ''))\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mdxcWnaUmtK"
      },
      "outputs": [],
      "source": [
        "# text classification\n",
        "def polarity_detection(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "def subjectivity_detection(text):\n",
        "    return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "def text_classification(words):\n",
        "    # polarity detection. It also creates a column for polarity\n",
        "    polarity_detection_udf = udf(polarity_detection, StringType())\n",
        "    words = words.withColumn(\"polarity\", polarity_detection_udf(\"word\"))\n",
        "    \n",
        "    # subjectivity detection. It also creates a column for subjectivity\n",
        "    subjectivity_detection_udf = udf(subjectivity_detection, StringType())\n",
        "    words = words.withColumn(\"subjectivity\", subjectivity_detection_udf(\"word\"))\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EyMqn2VUmtL"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # create Spark session\n",
        "    spark = SparkSession.builder\\\n",
        "            .appName(\"big_data_project_covid19_sentiment\")\\\n",
        "            .config(\"spark.cleaner.referenceTracking.cleanCheckpoints\", \"true\")\\\n",
        "            .getOrCreate()\n",
        "    \n",
        "    # read the tweet data from socket\n",
        "    lines = spark.readStream.format(\"socket\")\\\n",
        "            .option(\"host\", \"127.0.0.1\")\\\n",
        "            .option(\"port\", 5555)\\\n",
        "            .load()\n",
        "\n",
        "    # Preprocess the data\n",
        "    words = preprocessing(lines)\n",
        "    \n",
        "    # text classification to define polarity and subjectivity\n",
        "    words = text_classification(words)\n",
        "    words = words.repartition(1)\n",
        "    \n",
        "    # write to streaming dataframe\n",
        "    query = words.writeStream\\\n",
        "        .queryName(\"all_tweets\")\\\n",
        "        .outputMode(\"append\").format(\"parquet\")\\\n",
        "        .option(\"path\", \"./parquet\")\\\n",
        "        .option(\"checkpointLocation\", \"./check\")\\\n",
        "        .trigger(processingTime='60 seconds')\\\n",
        "        .start()\n",
        "    query.awaitTermination(900)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aO2OYsjEUmtO"
      },
      "outputs": [],
      "source": [
        "#! pip install pyarrow\n",
        "import pandas as pd\n",
        "parguet_file = r'C:\\Data Science\\MSc Data Science\\Big Data Management and Processing\\Project\\parquet'\n",
        "df=pd.read_parquet(parguet_file, engine='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB_OcZKeUmtQ",
        "outputId": "6cc11162-db0e-485a-860c-85d645bc1089"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>One of the weird things over the last few ye...</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>0.30333333333333334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Petition Do not make COVID vaccination a requi...</td>\n",
              "      <td>0.03333333333333333</td>\n",
              "      <td>0.06666666666666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you go to the South they have been over C...</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If you go to the South they have been over C...</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43161</th>\n",
              "      <td>Almost 2000 people a week are dying with cov...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43162</th>\n",
              "      <td>Spain has some of the most beautiful horse's â...</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43163</th>\n",
              "      <td>- Claim pandemic is over</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43164</th>\n",
              "      <td>âš½ï¸� In game fatigue</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43165</th>\n",
              "      <td>COVID related (19)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43166 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    word             polarity  \\\n",
              "0                                                                         0.0   \n",
              "1        One of the weird things over the last few ye...                -0.09   \n",
              "2      Petition Do not make COVID vaccination a requi...  0.03333333333333333   \n",
              "3        If you go to the South they have been over C...                 0.35   \n",
              "4        If you go to the South they have been over C...                 0.35   \n",
              "...                                                  ...                  ...   \n",
              "43161    Almost 2000 people a week are dying with cov...                  0.0   \n",
              "43162  Spain has some of the most beautiful horse's â...                0.675   \n",
              "43163                           - Claim pandemic is over                  0.0   \n",
              "43164                            âš½ï¸� In game fatigue                  -0.4   \n",
              "43165                                 COVID related (19)                  0.0   \n",
              "\n",
              "              subjectivity  \n",
              "0                      0.0  \n",
              "1      0.30333333333333334  \n",
              "2      0.06666666666666667  \n",
              "3                     0.55  \n",
              "4                     0.55  \n",
              "...                    ...  \n",
              "43161                  0.0  \n",
              "43162                 0.75  \n",
              "43163                  0.0  \n",
              "43164                  0.4  \n",
              "43165                  0.4  \n",
              "\n",
              "[43166 rows x 3 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "spark_sentiment_analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}